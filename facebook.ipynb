{
 "metadata": {
  "name": "",
  "signature": "sha256:8243cec2fed1fdbac2c54d1fe166e25571aec2c320618adeed8666e17332894b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pylab as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import random\n",
      "from matplotlib.colors import ListedColormap\n",
      "from collections import Counter\n",
      "\n",
      "from sklearn import cross_validation\n",
      "from sklearn import ensemble\n",
      "from sklearn import tree\n",
      "from sklearn import metrics\n",
      "from sklearn import feature_extraction\n",
      "from sklearn import feature_selection\n",
      "from sklearn import grid_search\n",
      "from sklearn import decomposition\n",
      "from sklearn import svm\n",
      "from sklearn import neighbors\n",
      "from sklearn import preprocessing\n",
      "from sklearn.grid_search import GridSearchCV"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Import raw data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "raw_bids = pd.read_csv('bids.csv')\n",
      "raw_training_data = pd.read_csv('train.csv')\n",
      "raw_test_data = pd.read_csv('test.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Set up bids data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training_bidder_ids = raw_training_data.bidder_id.values\n",
      "test_bidder_ids = raw_test_data.bidder_id.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bids = raw_bids.copy()\n",
      "\n",
      "bids['price'] = bids.groupby(['auction'])[['time']].transform(lambda x: np.array(x).argsort().argsort() + 1)\n",
      "bids['won_auction'] = bids.groupby(['auction'])['time'].apply(lambda x: x == max(x))\n",
      "\n",
      "bidder_id_outcome_map = dict(raw_training_data[['bidder_id', 'outcome']].values)\n",
      "bids['outcome'] = bids['bidder_id'].apply(lambda x: bidder_id_outcome_map.get(x, -1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time_group_1_min = 9631916842105263\n",
      "time_group_1_max = 9645558894736842\n",
      "\n",
      "time_group_2_min = 9695580000000000\n",
      "time_group_2_max = 9709222052631578\n",
      "\n",
      "time_group_3_min = 9759243157894736\n",
      "time_group_3_max = 9772885210526315\n",
      "\n",
      "bids['time_group'] = bids.time.apply(lambda x: (0 if x >= time_group_1_min and x <= time_group_1_max else\n",
      "                                                1 if x >= time_group_2_min and x <= time_group_2_max else\n",
      "                                                2))\n",
      "\n",
      "bids['time_group_1'] = bids.time.apply(lambda x: 1 if x >= time_group_1_min and x <= time_group_1_max else 0)\n",
      "bids['time_group_2'] = bids.time.apply(lambda x: 1 if x >= time_group_2_min and x <= time_group_2_max else 0)\n",
      "bids['time_group_3'] = bids.time.apply(lambda x: 1 if x >= time_group_3_min and x <= time_group_3_max else 0)\n",
      "\n",
      "def get_array_difference(x):\n",
      "    arr = np.array(x)\n",
      "    arr.sort()\n",
      "    return np.ediff1d(np.concatenate([arr[:1], arr]))\n",
      "bids['time_since_last_bid'] = bids.groupby(['auction', 'time_group'])[['time']].transform(get_array_difference)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Clean Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bids['country'] = bids['country'].fillna('none')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature Extraction"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Categorical Features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_categorical_features(records, threshold=1):    \n",
      "    print('Applying One Hot Encoding')\n",
      "    vec = feature_extraction.DictVectorizer()\n",
      "    one_hot_encoded = vec.fit_transform(records)\n",
      "    print('Size for Feature Vectors: {}\\n'.format(one_hot_encoded.shape))\n",
      "\n",
      "    print('Dropping features with low variance')\n",
      "    threshold = threshold * (1 - threshold)\n",
      "    print('Threshold = {}'.format(threshold))\n",
      "    selector = feature_selection.VarianceThreshold(threshold=threshold) \n",
      "    one_hot_encoded_and_thresholded = selector.fit_transform(one_hot_encoded)\n",
      "    print('Size for Feature Vectors: {}\\n'.format(one_hot_encoded_and_thresholded.shape))\n",
      "    \n",
      "    print('Running through PCA')\n",
      "    pca = decomposition.PCA()\n",
      "    one_hot_encoded_and_pca_variance_and_thresholded = pca.fit_transform(one_hot_encoded_and_thresholded.toarray())\n",
      "    print('Size for Feature Vectors: {}\\n'.format(one_hot_encoded_and_pca_variance_and_thresholded.shape))\n",
      "    \n",
      "    print('Removing mean and scaling variance')\n",
      "    features = preprocessing.StandardScaler().fit_transform(one_hot_encoded_and_pca_variance_and_thresholded)\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('Dataframe shape: {}\\n'.format(bids.shape))\n",
      "print('Available columns: {}'.format(bids.columns.values))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dataframe shape: (7656334, 17)\n",
        "\n",
        "Available columns: ['bid_id' 'bidder_id' 'auction' 'merchandise' 'device' 'time' 'country'\n",
        " 'ip' 'url' 'price' 'won_auction' 'outcome' 'time_group' 'time_group_1'\n",
        " 'time_group_2' 'time_group_3' 'time_since_last_bid']\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grouped_categorical_features = bids.groupby('bidder_id').aggregate(lambda x: ','.join(x))\n",
      "grouped_categorical_features = grouped_categorical_features.applymap(lambda x: Counter(x.split(',')))\n",
      "print('Grouped bids size: {}'.format(grouped_categorical_features.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Grouped bids size: (6614, 6)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns = ['auction', 'merchandise', 'device', 'country', 'ip', 'url']\n",
      "records = grouped_categorical_features[columns].sum(axis=1).values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = extract_categorical_features(records, 0.3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Applying One Hot Encoding\n",
        "Size for Feature Vectors: (6614, 4112954)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Dropping features with low variance\n",
        "Threshold = 0.21\n",
        "Size for Feature Vectors: (6614, 19639)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running through PCA\n",
        "Size for Feature Vectors: (6614, 6614)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Removing mean and scaling variance\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Time Based Features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temporal_features = bids.groupby('bidder_id')['won_auction', 'time_group_1', 'time_group_2', 'time_group_3'].sum().values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "number_of_times_starting_auction = bids.groupby('bidder_id')['time_since_last_bid'].apply(lambda x: sum(x == 0)).values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time_since_last_bid = bids.groupby('bidder_id')['time_since_last_bid'].mean().values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Compare Models"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels = grouped_categorical_features.reset_index()['bidder_id'].apply(lambda x: bidder_id_outcome_map.get(x, -1)).values\n",
      "\n",
      "train_index = np.where(labels != -1)\n",
      "test_index = np.where(labels == -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temporal_features = np.column_stack([temporal_features, time_since_last_bid, number_of_times_starting_auction])\n",
      "temporal_features = preprocessing.StandardScaler().fit_transform(temporal_features)\n",
      "\n",
      "temporal_features_train = temporal_features[train_index]\n",
      "temporal_features_test = temporal_features[test_index]\n",
      "\n",
      "print('Temporal Features')\n",
      "print('Feature Vectors Training: {}'.format(temporal_features_train.shape))\n",
      "print('Feature Vectors Testing: {}'.format(temporal_features_test.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Temporal Features\n",
        "Feature Vectors Training: (1984, 6)\n",
        "Feature Vectors Testing: (4630, 6)\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train, labels_train = features[train_index], labels[train_index]\n",
      "features_test = features[test_index]\n",
      "print('Categorical Features')\n",
      "print('Feature Vectors Training: {}'.format(features_train.shape))\n",
      "print('Feature Vectors Testing: {}'.format(features_test.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Categorical Features\n",
        "Feature Vectors Training: (1984, 6614)\n",
        "Feature Vectors Testing: (4630, 6614)\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = tree.DecisionTreeClassifier(class_weight='auto')\n",
      "clf.fit(features_train, labels_train)\n",
      "feature_importances = clf.feature_importances_\n",
      "\n",
      "print('Reduced Categorical Features')\n",
      "features_lower = np.squeeze(features[:,np.where(feature_importances > 0.01)])\n",
      "features_train_lower = features_lower[train_index]\n",
      "features_test_lower = features_lower[test_index]\n",
      "print('Feature Vectors Training: {}'.format(features_train_lower.shape))\n",
      "print('Feature Vectors Testing: {}'.format(features_test_lower.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reduced Categorical Features\n",
        "Feature Vectors Training: (1984, 18)\n",
        "Feature Vectors Testing: (4630, 18)\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_features = np.column_stack([temporal_features, features_lower])\n",
      "\n",
      "print('Combined Features')\n",
      "combined_features = np.column_stack([temporal_features, features_lower])\n",
      "combined_features_train = combined_features[train_index]\n",
      "combined_features_test = combined_features[test_index]\n",
      "print('Feature Vectors Training: {}'.format(combined_features_train.shape))\n",
      "print('Feature Vectors Testing: {}'.format(combined_features_test.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Combined Features\n",
        "Feature Vectors Training: (1984, 24)\n",
        "Feature Vectors Testing: (4630, 24)\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_accuracy_auc_scores(clf, features, labels, cv=5, n_jobs=-1):\n",
      "    scores = cross_validation.cross_val_score(clf, features, labels, scoring='roc_auc', cv=cv, n_jobs=n_jobs)\n",
      "    print('auc scores: {}'.format(scores))\n",
      "\n",
      "    scores = cross_validation.cross_val_score(clf, features, labels, cv=cv, n_jobs=n_jobs)\n",
      "    print('accuracy scores: {}'.format(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_accuracy_auc_scores_for_all_features(clf, clf_name='Classifier'):\n",
      "    print(clf_name)\n",
      "    print_accuracy_auc_scores(clf, features_train, labels_train)\n",
      "\n",
      "    print('\\n{} Reduced'.format(clf_name))\n",
      "    print_accuracy_auc_scores(clf, features_train_lower, labels_train)\n",
      "\n",
      "    print('\\n{} Temporal'.format(clf_name))\n",
      "    print_accuracy_auc_scores(clf, temporal_features_train, labels_train)\n",
      "\n",
      "    print('\\n{} Combined'.format(clf_name))\n",
      "    print_accuracy_auc_scores(clf, combined_features_train, labels_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_depth = 3\n",
      "clf = tree.DecisionTreeClassifier(class_weight='auto', max_depth=max_depth)\n",
      "print_accuracy_auc_scores_for_all_features(clf, 'Decision Tree')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Decision Tree\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.72761147  0.68686677  0.71789514  0.6412234   0.57839096]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.77889447  0.77078086  0.77833753  0.79040404  0.81060606]\n",
        "\n",
        "Decision Tree Reduced\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.82171277  0.91508359  0.84340172  0.78570479  0.82845745]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.7638191   0.80856423  0.78085642  0.78282828  0.78535354]\n",
        "\n",
        "Decision Tree Temporal\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.7152962   0.70972644  0.66824975  0.74926862  0.85365691]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.75628141  0.78085642  0.71788413  0.81313131  0.81818182]\n",
        "\n",
        "Decision Tree Combined\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.82423898  0.91508359  0.79299645  0.78570479  0.82845745]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.76633166  0.80856423  0.78085642  0.78282828  0.78535354]\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = ensemble.RandomForestClassifier(n_estimators=100, class_weight='auto')\n",
      "\n",
      "param_grid = dict(max_depth=list(range(1,20)),\n",
      "                  criterion=['gini', 'entropy'],\n",
      "                  class_weight=['auto', 'subsample'],\n",
      "                  min_samples_leaf=[1,2,3,4,5,6,7,8,9,10],\n",
      "                  min_samples_split=[2,3,4,5,6,7,8,9,10],\n",
      "                  oob_score=[True, False],\n",
      "                  )\n",
      "clf = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=-1, scoring='roc_auc')\n",
      "clf.fit(features_train_lower, labels_train)\n",
      "clf.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "RandomForestClassifier(bootstrap=True, class_weight='subsample',\n",
        "            criterion='gini', max_depth=19, max_features='auto',\n",
        "            max_leaf_nodes=None, min_samples_leaf=3, min_samples_split=4,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0,\n",
        "            warm_start=False)"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_estimators = 100\n",
      "max_depth = 19\n",
      "criterion = 'gini'\n",
      "min_samples_leaf = 3\n",
      "min_samples_split = 4\n",
      "class_weight = 'subsample'\n",
      "oob_score = False\n",
      "clf = ensemble.RandomForestClassifier(criterion=criterion, n_estimators=n_estimators, oob_score=oob_score,\n",
      "                                      class_weight=class_weight, max_depth=max_depth,\n",
      "                                      min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split)\n",
      "print_accuracy_auc_scores_for_all_features(clf, 'Random Forest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Random Forest\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.85587975  0.90273556  0.84986069  0.87154255  0.85578457]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.94723618  0.94710327  0.94962217  0.94949495  0.94949495]\n",
        "\n",
        "Random Forest Reduced\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.92572944  0.92337893  0.91514691  0.93244681  0.92087766]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.94974874  0.94710327  0.93702771  0.94444444  0.92929293]\n",
        "\n",
        "Random Forest Temporal\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.85543767  0.89842958  0.85005066  0.88962766  0.85445479]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.92964824  0.92947103  0.93198992  0.94444444  0.92424242]\n",
        "\n",
        "Random Forest Combined\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.91031957  0.93275076  0.92515198  0.93098404  0.91382979]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.94723618  0.94206549  0.94710327  0.9520202   0.94444444]\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_estimators = 100\n",
      "max_depth = 8\n",
      "criterion = 'gini'\n",
      "min_samples_leaf = 9\n",
      "min_samples_split = 6\n",
      "class_weight = 'subsample'\n",
      "oob_score = True\n",
      "clf = ensemble.RandomForestClassifier(criterion=criterion, n_estimators=n_estimators, oob_score=oob_score,\n",
      "                                      class_weight=class_weight, max_depth=max_depth,\n",
      "                                      min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split)\n",
      "print_accuracy_auc_scores_for_all_features(clf, 'Random Forest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Random Forest\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.87621574  0.88133232  0.85663627  0.8787234   0.86555851]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.89447236  0.90680101  0.95214106  0.9469697   0.92929293]\n",
        "\n",
        "Random Forest Reduced\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.91537198  0.91919959  0.91578014  0.93191489  0.8962766 ]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.87688442  0.89924433  0.89924433  0.90656566  0.87121212]\n",
        "\n",
        "Random Forest Temporal\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.84710117  0.90286221  0.85676292  0.9037234   0.84268617]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.88442211  0.87657431  0.87153652  0.87626263  0.87121212]\n",
        "\n",
        "Random Forest Combined\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.9058987   0.9276849   0.90083587  0.92406915  0.89614362]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.88442211  0.90680101  0.88664987  0.89393939  0.88131313]\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_estimators = 100\n",
      "max_depth = 14\n",
      "criterion = 'gini'\n",
      "min_samples_leaf = 4\n",
      "min_samples_split = 3\n",
      "class_weight = 'subsample'\n",
      "clf = ensemble.RandomForestClassifier(criterion=criterion, n_estimators=n_estimators, oob_score=True,\n",
      "                                      class_weight=class_weight, max_depth=max_depth,\n",
      "                                      min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split)\n",
      "print_accuracy_auc_scores_for_all_features(clf, 'Random Forest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Random Forest\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.86857395  0.86030902  0.85283688  0.85292553  0.84481383]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.95226131  0.94710327  0.94962217  0.94949495  0.94949495]\n",
        "\n",
        "Random Forest Reduced\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.91726664  0.92375887  0.93034448  0.9293883   0.90359043]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.94221106  0.93198992  0.92695214  0.94191919  0.91666667]\n",
        "\n",
        "Random Forest Temporal\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.85550082  0.90450861  0.86208207  0.89481383  0.83457447]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.92964824  0.92443325  0.92443325  0.91919192  0.91666667]\n",
        "\n",
        "Random Forest Combined\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.89149931  0.93920973  0.92033941  0.92978723  0.89800532]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.94472362  0.93450882  0.93450882  0.9520202   0.92171717]\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = ensemble.ExtraTreesClassifier(n_estimators=100, class_weight='auto')\n",
      "\n",
      "param_grid = dict(max_depth=list(range(1,20)),\n",
      "                  criterion=['gini', 'entropy'],\n",
      "                  class_weight=['auto', 'subsample'],\n",
      "                  min_samples_split=[2,3,4,5,6,7,8,9,10])\n",
      "clf = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=-1, scoring='roc_auc')\n",
      "clf.fit(combined_features_train, labels_train)\n",
      "clf.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 212,
       "text": [
        "ExtraTreesClassifier(bootstrap=False, class_weight='auto', criterion='gini',\n",
        "           max_depth=18, max_features='auto', max_leaf_nodes=None,\n",
        "           min_samples_leaf=1, min_samples_split=10,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
        "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
       ]
      }
     ],
     "prompt_number": 212
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = ensemble.ExtraTreesClassifier(n_estimators=100, class_weight='auto')\n",
      "\n",
      "param_grid = dict(max_depth=list(range(1,20)),\n",
      "                  criterion=['gini', 'entropy'],\n",
      "                  class_weight=['auto', 'subsample'],\n",
      "                  min_samples_leaf=[1,2,3,4,5,6,7,8,9,10],\n",
      "                  min_samples_split=[2,3,4,5,6,7,8,9,10],\n",
      "                  warm_start=[False],\n",
      "                  oob_score=[True],\n",
      "                  bootstrap=[True])\n",
      "clf = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=-1, scoring='roc_auc')\n",
      "clf.fit(combined_features_train, labels_train)\n",
      "clf.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 214,
       "text": [
        "ExtraTreesClassifier(bootstrap=True, class_weight='subsample',\n",
        "           criterion='gini', max_depth=17, max_features='auto',\n",
        "           max_leaf_nodes=None, min_samples_leaf=2, min_samples_split=4,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
        "           oob_score=True, random_state=None, verbose=0, warm_start=False)"
       ]
      }
     ],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = ensemble.ExtraTreesClassifier(n_estimators=100, class_weight='auto')\n",
      "\n",
      "param_grid = dict(max_depth=list(range(1,20)),\n",
      "                  criterion=['gini', 'entropy'],\n",
      "                  class_weight=['auto', 'subsample'],\n",
      "                  min_samples_leaf=[1,2,3,4,5,6,7,8,9,10],\n",
      "                  min_samples_split=[2,3,4,5,6,7,8,9,10],\n",
      "                  oob_score=[True],\n",
      "                  bootstrap=[True])\n",
      "clf = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=-1, scoring='roc_auc')\n",
      "clf.fit(features_train_lower, labels_train)\n",
      "clf.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "ExtraTreesClassifier(bootstrap=True, class_weight='auto', criterion='gini',\n",
        "           max_depth=18, max_features='auto', max_leaf_nodes=None,\n",
        "           min_samples_leaf=1, min_samples_split=8,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
        "           oob_score=True, random_state=None, verbose=0, warm_start=False)"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_estimators = 100\n",
      "class_weight = 'auto'\n",
      "max_depth = 18\n",
      "min_samples_split = 8\n",
      "oob_score = True\n",
      "bootstrap = True\n",
      "\n",
      "clf = ensemble.ExtraTreesClassifier(n_estimators=n_estimators, class_weight=class_weight, max_depth=max_depth,\n",
      "                                    min_samples_split=min_samples_split, oob_score=oob_score, bootstrap=bootstrap)\n",
      "print_accuracy_auc_scores_for_all_features(clf, 'Extra Trees')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Extra Trees\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.86257421  0.8766464   0.83257345  0.86289894  0.83796543]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.82914573  0.8488665   0.86901763  0.86363636  0.85606061]\n",
        "\n",
        "Extra Trees Reduced\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.86762663  0.908308    0.87006079  0.88710106  0.88324468]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.8919598   0.89420655  0.89924433  0.88636364  0.87121212]\n",
        "\n",
        "Extra Trees Temporal\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.86825818  0.89842958  0.76735056  0.86050532  0.87792553]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.90954774  0.91687657  0.89924433  0.9040404   0.91414141]\n",
        "\n",
        "Extra Trees Combined\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.8781104   0.920846    0.875       0.91010638  0.89202128]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.90954774  0.92191436  0.91687657  0.92171717  0.90909091]\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_estimators = 100\n",
      "class_weight = 'subsample'\n",
      "min_samples_leaf = 2\n",
      "min_samples_split = 50\n",
      "max_depth=None\n",
      "\n",
      "clf = ensemble.ExtraTreesClassifier(n_estimators=n_estimators, class_weight=class_weight, max_depth=max_depth,\n",
      "                                    min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split)\n",
      "print_accuracy_auc_scores_for_all_features(clf, 'Extra Trees')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Extra Trees\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.85884805  0.90488855  0.83320669  0.87699468  0.86130319]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.8919598   0.93702771  0.89168766  0.90151515  0.89393939]\n",
        "\n",
        "Extra Trees Reduced\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.91006694  0.91666667  0.88057244  0.9025266   0.89109043]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.82663317  0.85390428  0.82115869  0.83585859  0.84090909]\n",
        "\n",
        "Extra Trees Temporal\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.83983832  0.90944782  0.83466312  0.89574468  0.82765957]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.79899497  0.80604534  0.79848866  0.80050505  0.81818182]\n",
        "\n",
        "Extra Trees Combined\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc scores: [ 0.90968801  0.92515198  0.87791287  0.91449468  0.89095745]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy scores: [ 0.81155779  0.84634761  0.82871537  0.82070707  0.84090909]\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Run for test data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum_value = 0\n",
      "while sum_value < 1:\n",
      "    n_estimators = 100\n",
      "    class_weight = 'subsample'\n",
      "    min_samples_leaf = 2\n",
      "    min_samples_split = 50\n",
      "    max_depth=None\n",
      "\n",
      "    clf = ensemble.ExtraTreesClassifier(n_estimators=n_estimators, class_weight=class_weight, max_depth=max_depth,\n",
      "                                        min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split)\n",
      "    clf.fit(combined_features_train, labels_train)\n",
      "    prediction = clf.predict_proba(combined_features_test)[:,1]\n",
      "    sum_value = sum(prediction)\n",
      "    print('Is robot: {:.2f}%'.format(100 * sum_value / len(prediction)))\n",
      "    print(sum_value)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is robot: 23.22%\n",
        "1074.94080405\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output = list(zip(grouped_categorical_features.index.values[test_index], prediction))\n",
      "output = pd.DataFrame(output, columns=['bidder_id', 'prediction'])\n",
      "output = output.set_index('bidder_id')\n",
      "\n",
      "nan_output = [[x, 0] for x in raw_test_data.bidder_id.unique()]\n",
      "nan_output = pd.DataFrame(nan_output, columns=['bidder_id', 'prediction'])\n",
      "nan_output = nan_output.set_index('bidder_id')\n",
      "\n",
      "output = output + nan_output\n",
      "output = output.fillna(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output.to_csv('output.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    }
   ],
   "metadata": {}
  }
 ]
}